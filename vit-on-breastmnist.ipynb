{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-06T21:56:03.477591Z","iopub.execute_input":"2025-03-06T21:56:03.477892Z","iopub.status.idle":"2025-03-06T21:56:03.804678Z","shell.execute_reply.started":"2025-03-06T21:56:03.477872Z","shell.execute_reply":"2025-03-06T21:56:03.803826Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install medmnist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:01:17.462351Z","iopub.execute_input":"2025-03-06T22:01:17.462651Z","iopub.status.idle":"2025-03-06T22:01:23.306730Z","shell.execute_reply.started":"2025-03-06T22:01:17.462629Z","shell.execute_reply":"2025-03-06T22:01:23.305877Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting medmnist\n  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.25.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.67.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (11.0.0)\nCollecting fire (from medmnist)\n  Downloading fire-0.7.0.tar.gz (87 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cu121)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->medmnist) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2025.1)\nRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.12.12)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.2)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->medmnist) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->medmnist) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->medmnist) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->medmnist) (2024.2.0)\nDownloading medmnist-3.0.2-py3-none-any.whl (25 kB)\nBuilding wheels for collected packages: fire\n  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=26f4cfcf76c992e72f6b63c9a90e457359e7b9123ff0548f629fb4ca66dc7fe2\n  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\nSuccessfully built fire\nInstalling collected packages: fire, medmnist\nSuccessfully installed fire-0.7.0 medmnist-3.0.2\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import  medmnist \nfrom medmnist import BreastMNIST\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:04:52.443143Z","iopub.execute_input":"2025-03-06T22:04:52.443486Z","iopub.status.idle":"2025-03-06T22:04:56.576605Z","shell.execute_reply.started":"2025-03-06T22:04:52.443462Z","shell.execute_reply":"2025-03-06T22:04:56.575764Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"dataset = BreastMNIST(split='train', download=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:06:28.457009Z","iopub.execute_input":"2025-03-06T22:06:28.457317Z","iopub.status.idle":"2025-03-06T22:06:28.468127Z","shell.execute_reply.started":"2025-03-06T22:06:28.457293Z","shell.execute_reply":"2025-03-06T22:06:28.467245Z"}},"outputs":[{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:07:15.657524Z","iopub.execute_input":"2025-03-06T22:07:15.657848Z","iopub.status.idle":"2025-03-06T22:07:15.662690Z","shell.execute_reply.started":"2025-03-06T22:07:15.657820Z","shell.execute_reply":"2025-03-06T22:07:15.661645Z"}},"outputs":[{"name":"stdout","text":"Dataset BreastMNIST of size 28 (breastmnist)\n    Number of datapoints: 546\n    Root location: /root/.medmnist\n    Split: train\n    Task: binary-class\n    Number of channels: 1\n    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n    License: CC BY 4.0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport cv2\nimport torch.nn as nn\nfrom transformers import ViTModel, ViTConfig\nfrom torchvision import transforms\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n#Pretrained model checkpoint\nmodel_checkpoint = 'google/vit-base-patch16-224-in21k'\n     \n\nclass ImageDataset(torch.utils.data.Dataset):\n\n  def __init__(self, input_data):\n        \n      self.input_data = input_data\n      # Transform input data\n      self.transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Resize((224, 224), antialias=True),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], \n                             std=[0.5, 0.5, 0.5])\n        ])\n\n  def __len__(self):\n      return len(self.input_data)\n    \n  def get_images(self, idx):\n      return self.transform(self.input_data[idx]['image'])\n  \n  def get_labels(self, idx):\n      return self.input_data[idx]['label']\n  \n  def __getitem__(self, idx):\n      # Get input data in a batch\n      train_images = self.get_images(idx)\n      train_labels = self.get_labels(idx)\n\n      return train_images, train_labels\n     \n\nclass ViT(nn.Module):\n\n  def __init__(self, config=ViTConfig(), num_labels=20, \n               model_checkpoint='google/vit-base-patch16-224-in21k'):\n\n        super(ViT, self).__init__()\n\n        self.vit = ViTModel.from_pretrained(model_checkpoint, add_pooling_layer=False)\n        self.classifier = (\n            nn.Linear(config.hidden_size, num_labels) \n        )\n\n  def forward(self, x):\n\n    x = self.vit(x)['last_hidden_state']\n    # Use the embedding of [CLS] token\n    output = self.classifier(x[:, 0, :])\n\n    return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:09:40.286192Z","iopub.execute_input":"2025-03-06T22:09:40.286648Z","iopub.status.idle":"2025-03-06T22:09:53.776536Z","shell.execute_reply.started":"2025-03-06T22:09:40.286610Z","shell.execute_reply":"2025-03-06T22:09:53.775600Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def model_train(dataset, epochs, learning_rate, bs):\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    # Load nodel, loss function, and optimizer\n    model = ViT().to(device)\n    criterion = nn.CrossEntropyLoss().to(device)\n    optimizer = Adam(model.parameters(), lr=learning_rate)\n\n    # Load batch image\n    train_dataset = ImageDataset(dataset)\n    train_dataloader = DataLoader(train_dataset, num_workers=1, batch_size=bs, shuffle=True)\n\n    # Fine tuning loop\n    for i in range(epochs):\n        total_acc_train = 0\n        total_loss_train = 0.0\n\n        for train_image, train_label in tqdm(train_dataloader):\n            output = model(train_image.to(device))\n            loss = criterion(output, train_label.to(device))\n            acc = (output.argmax(dim=1) == train_label.to(device)).sum().item()\n            total_acc_train += acc\n            total_loss_train += loss.item()\n\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n        print(f'Epochs: {i + 1} | Loss: {total_loss_train / len(train_dataset): .3f} | Accuracy: {total_acc_train / len(train_dataset): .3f}')\n\n    return model\n\n# Hyperparameters\nEPOCHS = 10\nLEARNING_RATE = 1e-4\nBATCH_SIZE = 8\n\n# Train the model\ntrained_model = model_train(dataset['train'], EPOCHS, LEARNING_RATE, BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:10:55.518766Z","iopub.execute_input":"2025-03-06T22:10:55.519518Z","iopub.status.idle":"2025-03-06T22:10:55.764149Z","shell.execute_reply.started":"2025-03-06T22:10:55.519488Z","shell.execute_reply":"2025-03-06T22:10:55.763074Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-5ea69ef590d5>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/medmnist/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mL\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msingle\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"],"ename":"IndexError","evalue":"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nfrom transformers import ViTModel\nfrom torchvision import transforms\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport medmnist\nfrom medmnist import BreastMNIST\n\n# Pretrained model checkpoint\nMODEL_CHECKPOINT = 'google/vit-base-patch16-224-in21k'\n\n# Define constants\nNUM_CLASSES = 2  # BreastMNIST is a binary classification task\nBATCH_SIZE = 64\nEPOCHS = 10\n\nclass BreastMNISTDataset(Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),  # Resize for ViT\n            transforms.Grayscale(3),  # Convert grayscale to 3-channel RGB\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n        ])\n    \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, idx):\n        img, label = self.dataset[idx]\n        img = self.transform(img)  # Apply transformations\n        label = torch.tensor(label, dtype=torch.long).squeeze()  # Ensure label shape\n        return img, label\n\n\n# Load BreastMNIST dataset\ntrain_data = BreastMNIST(split='train', download=True)\ntest_data = BreastMNIST(split='test', download=True)\n\n# Create dataset instances\ntrain_dataset = BreastMNISTDataset(train_data)\ntest_dataset = BreastMNISTDataset(test_data)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# Define ViT model for classification\nclass ViTClassifier(nn.Module):\n    def __init__(self, num_classes=NUM_CLASSES):\n        super(ViTClassifier, self).__init__()\n        self.vit = ViTModel.from_pretrained(MODEL_CHECKPOINT, add_pooling_layer=False)\n        self.classifier = nn.Linear(self.vit.config.hidden_size, num_classes)\n\n    def forward(self, x):\n        x = self.vit(x)['last_hidden_state']\n        output = self.classifier(x[:, 0, :])  # Use CLS token embedding\n        return output\n\n# Initialize model, optimizer, and loss function\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ViTClassifier(NUM_CLASSES).to(device)\noptimizer = Adam(model.parameters(), lr=2e-5)\ncriterion = nn.CrossEntropyLoss()\n\n# Training function\ndef train(model, dataloader, optimizer, criterion, epochs=EPOCHS):\n    model.train()\n    for epoch in range(epochs):\n        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        total_loss = 0\n        for images, labels in loop:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            loop.set_postfix(loss=total_loss / len(dataloader))\n    print(\"Training complete.\")\n\n# Train the model\ntrain(model, train_loader, optimizer, criterion, epochs=EPOCHS)\n\n# Evaluate model\ndef evaluate(model, dataloader):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            predictions = torch.argmax(outputs, dim=1)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n\n# Evaluate on test set\nevaluate(model, test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T22:46:18.768588Z","iopub.execute_input":"2025-03-06T22:46:18.768918Z","iopub.status.idle":"2025-03-06T22:48:06.562950Z","shell.execute_reply.started":"2025-03-06T22:46:18.768896Z","shell.execute_reply":"2025-03-06T22:48:06.562099Z"}},"outputs":[{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/breastmnist.npz\nUsing downloaded and verified file: /root/.medmnist/breastmnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTModel: ['pooler.dense.bias', 'pooler.dense.weight']\n- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nEpoch 1/10: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it, loss=0.597] \nEpoch 2/10: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it, loss=0.508] \nEpoch 3/10: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it, loss=0.454] \nEpoch 4/10: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it, loss=0.375] \nEpoch 5/10: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it, loss=0.312] \nEpoch 6/10: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it, loss=0.244] \nEpoch 7/10: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it, loss=0.194] \nEpoch 8/10: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it, loss=0.153] \nEpoch 9/10: 100%|██████████| 9/9 [00:10<00:00,  1.19s/it, loss=0.122] \nEpoch 10/10: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it, loss=0.102]  \n","output_type":"stream"},{"name":"stdout","text":"Training complete.\nTest Accuracy: 85.26%\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nfrom transformers import ViTModel, ViTConfig\nfrom torchvision import transforms\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport medmnist\nfrom medmnist import BreastMNIST\n\n# Define constants\nNUM_CLASSES = 2  # BreastMNIST is a binary classification task\nBATCH_SIZE = 32\nEPOCHS = 10\n\n# Define dataset class\nclass BreastMNISTDataset(Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),  # Resize for ViT\n            transforms.Grayscale(3),  # Convert grayscale to 3-channel RGB\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n        ])\n    \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, idx):\n        img, label = self.dataset[idx]\n        img = self.transform(img)  # Apply transformations\n        label = torch.tensor(label, dtype=torch.long).squeeze()  # Ensure label shape\n        return img, label\n\n# Load BreastMNIST dataset\ntrain_data = BreastMNIST(split='train', download=True)\ntest_data = BreastMNIST(split='test', download=True)\n\n# Create dataset instances\ntrain_dataset = BreastMNISTDataset(train_data)\ntest_dataset = BreastMNISTDataset(test_data)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# Define ViT model for classification from scratch (no pre-trained weights)\nclass ViTClassifier(nn.Module):\n    def __init__(self, num_classes=NUM_CLASSES):\n        super(ViTClassifier, self).__init__()\n        # Use a custom configuration for the model (e.g., 224x224 image input size)\n        config = ViTConfig(\n            hidden_size=768,\n            num_attention_heads=12,\n            num_hidden_layers=12,\n            intermediate_size=3072,\n            image_size=224,\n            patch_size=16,\n            num_channels=3,  # RGB\n            num_labels=num_classes  # Set for binary classification\n        )\n        self.vit = ViTModel(config)  # Initialize without pre-trained weights\n        self.classifier = nn.Linear(config.hidden_size, num_classes)\n\n    def forward(self, x):\n        x = self.vit(x)['last_hidden_state']\n        output = self.classifier(x[:, 0, :])  # Use CLS token embedding\n        return output\n\n# Initialize model, optimizer, and loss function\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ViTClassifier(NUM_CLASSES).to(device)\noptimizer = AdamW(model.parameters(), lr=1e-4)\ncriterion = nn.CrossEntropyLoss()\n\n# Training function\ndef train(model, dataloader, optimizer, criterion, epochs=EPOCHS):\n    model.train()\n    for epoch in range(epochs):\n        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        total_loss = 0\n        for images, labels in loop:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            loop.set_postfix(loss=total_loss / len(dataloader))\n    print(\"Training complete.\")\n\n# Train the model\ntrain(model, train_loader, optimizer, criterion, epochs=EPOCHS)\n\n# Evaluate model\ndef evaluate(model, dataloader):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            predictions = torch.argmax(outputs, dim=1)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n\n# Evaluate on test set\nevaluate(model, test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T23:06:40.074780Z","iopub.execute_input":"2025-03-06T23:06:40.075152Z","iopub.status.idle":"2025-03-06T23:08:31.337084Z","shell.execute_reply.started":"2025-03-06T23:06:40.075128Z","shell.execute_reply":"2025-03-06T23:08:31.336181Z"}},"outputs":[{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/breastmnist.npz\nUsing downloaded and verified file: /root/.medmnist/breastmnist.npz\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 18/18 [00:10<00:00,  1.67it/s, loss=1.1]  \nEpoch 2/10: 100%|██████████| 18/18 [00:10<00:00,  1.67it/s, loss=0.642]\nEpoch 3/10: 100%|██████████| 18/18 [00:10<00:00,  1.67it/s, loss=0.572]\nEpoch 4/10: 100%|██████████| 18/18 [00:10<00:00,  1.66it/s, loss=0.586]\nEpoch 5/10: 100%|██████████| 18/18 [00:10<00:00,  1.66it/s, loss=0.605]\nEpoch 6/10: 100%|██████████| 18/18 [00:10<00:00,  1.65it/s, loss=0.56] \nEpoch 7/10: 100%|██████████| 18/18 [00:10<00:00,  1.65it/s, loss=0.589]\nEpoch 8/10: 100%|██████████| 18/18 [00:10<00:00,  1.66it/s, loss=0.585]\nEpoch 9/10: 100%|██████████| 18/18 [00:10<00:00,  1.66it/s, loss=0.546]\nEpoch 10/10: 100%|██████████| 18/18 [00:10<00:00,  1.65it/s, loss=0.55] \n","output_type":"stream"},{"name":"stdout","text":"Training complete.\nTest Accuracy: 73.08%\n","output_type":"stream"}],"execution_count":38}]}